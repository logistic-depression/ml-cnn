{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Baseline for machine learning project on road segmentation.\n",
    "This simple baseline consits of a CNN with two convolutional+pooling layers with a soft-max loss\n",
    "\n",
    "Credits: Aurelien Lucchi, ETH ZÃ¼rich\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import code\n",
    "import tensorflow.python.platform\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "\n",
    "NUM_CHANNELS = 3  # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "\n",
    "TOTAL_DATA_SIZE=100\n",
    "DATA_IDS = numpy.array([i for i in range(1,TOTAL_DATA_SIZE+1) if i != 33])\n",
    "TRAIN_SIZE = 89\n",
    "VALIDATE_SIZE = 10\n",
    "ROTATION = True\n",
    "\n",
    "GROUPED_BATCH_SIZE = 3\n",
    "\n",
    "numpy.random.seed(42)\n",
    "IDS = numpy.random.choice(DATA_IDS, size=(TRAIN_SIZE+VALIDATE_SIZE), replace=False, p=None)\n",
    "TRAIN_IDS = IDS[:TRAIN_SIZE]\n",
    "VALIDATE_IDS = IDS[TRAIN_SIZE:]\n",
    "if ROTATION:\n",
    "    TRAIN_IDS = numpy.array([j for i in TRAIN_IDS for j in range(i, TOTAL_DATA_SIZE*8+1, TOTAL_DATA_SIZE) ])\n",
    "    VALIDATE_IDS = numpy.array([j for i in VALIDATE_IDS for j in range(i, TOTAL_DATA_SIZE*8+1, TOTAL_DATA_SIZE) ])\n",
    "\n",
    "\n",
    "#VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 16  # 64\n",
    "NUM_EPOCHS = 100\n",
    "RESTORE_MODEL = False  # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 0\n",
    "\n",
    "# Set image patch size in pixels\n",
    "# IMG_PATCH_SIZE should be a multiple of 4\n",
    "# image size should be an integer multiple of this number!\n",
    "IMG_PATCH_SIZE = 16\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', '/tmp/segment_aerial_images',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712,), (80,), array([ 64, 164, 264]), array([ 92, 192, 292]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_IDS.shape, VALIDATE_IDS.shape, TRAIN_IDS[:3], VALIDATE_IDS[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from a given image\n",
    "def img_crop(im, w, h):\n",
    "    h_shift = (GROUPED_BATCH_SIZE // 2)*h\n",
    "    w_shift = (GROUPED_BATCH_SIZE // 2)*w\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(h_shift, imgheight - h_shift, h):\n",
    "        for j in range(w_shift, imgwidth - w_shift, w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[\n",
    "                    j-w_shift:j+w+w_shift,\n",
    "                    i-h_shift:i+h+h_shift,\n",
    "                    :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, image_ids):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    for i in image_ids:\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            #print('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(imgs)\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH/IMG_PATCH_SIZE)*(IMG_HEIGHT/IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [img_crop(imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = [img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))]\n",
    "\n",
    "    return numpy.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a label to a patch v\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25  # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = numpy.sum(v)\n",
    "    if df > foreground_threshold:  # road\n",
    "        return [0, 1]\n",
    "    else:  # bgrd\n",
    "        return [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract label images\n",
    "def extract_labels(filename, image_ids):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in image_ids:\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            #print('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = numpy.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = numpy.asarray([value_to_class(numpy.mean(data[i])) for i in range(len(data))])\n",
    "\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    \"\"\"Return the error rate based on dense predictions and 1-hot labels.\"\"\"\n",
    "    return 100.0 - (\n",
    "        100.0 *\n",
    "        numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1)) /\n",
    "        predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions from neural network to a file\n",
    "def write_predictions_to_file(predictions, labels, filename):\n",
    "    max_labels = numpy.argmax(labels, 1)\n",
    "    max_predictions = numpy.argmax(predictions, 1)\n",
    "    file = open(filename, \"w\")\n",
    "    n = predictions.shape[0]\n",
    "    for i in range(0, n):\n",
    "        file.write(max_labels(i) + ' ' + max_predictions(i))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print predictions from neural network\n",
    "def print_predictions(predictions, labels):\n",
    "    max_labels = numpy.argmax(labels, 1)\n",
    "    max_predictions = numpy.argmax(predictions, 1)\n",
    "    print(str(max_labels) + ' ' + str(max_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array of labels to an image\n",
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    array_labels = numpy.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0, imgheight, h):\n",
    "        for j in range(0, imgwidth, w):\n",
    "            if labels[idx][0] > 0.5:  # bgrd\n",
    "                l = 0\n",
    "            else:\n",
    "                l = 1\n",
    "            array_labels[j:j+w, i:i+h] = l\n",
    "            idx = idx + 1\n",
    "    return array_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_float_to_uint8(img):\n",
    "    rimg = img - numpy.min(img)\n",
    "    rimg = (rimg / numpy.max(rimg) * PIXEL_DEPTH).round().astype(numpy.uint8)\n",
    "    return rimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_images(img, gt_img):\n",
    "    n_channels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if n_channels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)\n",
    "        gt_img_3c[:, :, 0] = gt_img8\n",
    "        gt_img_3c[:, :, 1] = gt_img8\n",
    "        gt_img_3c[:, :, 2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img_overlay(img, predicted_img):\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    color_mask = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "    color_mask[:, :, 0] = predicted_img*PIXEL_DEPTH\n",
    "\n",
    "    img8 = img_float_to_uint8(img)\n",
    "    background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n",
    "    overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n",
    "    new_img = Image.blend(background, overlay, 0.2)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcor(y_true, y_pred):\n",
    "    #matthews_correlation\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "    \n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "    \n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    \n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def bcor(y_true, y_pred):\n",
    "    pp = K.mean(K.round(K.clip(y_pred, 0, 1)))\n",
    "    pn = 1 - pp\n",
    "    pos = K.mean(K.round(K.clip(y_true, 0, 1)))\n",
    "    neg = 1 - pos\n",
    "    \n",
    "    tp = K.mean(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    fp = pp - tp\n",
    "    \n",
    "    fn = pos - tp\n",
    "    tn = pn - fn\n",
    "    \n",
    "    return (tp - (pp*pos)) / (pos - (pos*pos))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    pp = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = tp / (pp + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = tp / (pos + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    pp = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = tp / (pp + K.epsilon())\n",
    "    \n",
    "    pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = tp / (pos + K.epsilon())\n",
    "    \n",
    "    return 2*((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'training/'\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/'\n",
    "test_data_filename = 'test_set_images/'\n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, TRAIN_IDS)\n",
    "validate_data = extract_data(train_data_filename, VALIDATE_IDS)\n",
    "\n",
    "train_labels = extract_labels(train_labels_filename, TRAIN_IDS)\n",
    "validate_labels = extract_labels(train_labels_filename, VALIDATE_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points per class before balancing: c0 = 277680 c1 = 98968\n",
      "Balancing training data...\n",
      "197936\n",
      "(376648, 48, 48, 3)\n",
      "Number of data points per class after balancing: c0 = 98968 c1 = 98968\n",
      "197936\n",
      "(197936, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = NUM_EPOCHS\n",
    "\n",
    "c0 = 0  # bgrd\n",
    "c1 = 0  # road\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print('Number of data points per class before balancing: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "\n",
    "print('Balancing training data...')\n",
    "min_c = min(c0, c1)\n",
    "idx0 = [i for i, j in enumerate(train_labels) if j[0] == 1]\n",
    "idx1 = [i for i, j in enumerate(train_labels) if j[1] == 1]\n",
    "new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "print(len(new_indices))\n",
    "print(train_data.shape)\n",
    "train_data = train_data[new_indices, :, :, :]\n",
    "train_labels = train_labels[new_indices]\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "c0 = 0\n",
    "c1 = 0\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print('Number of data points per class after balancing: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "print(len(new_indices))\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tn = tf.keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=SEED)\n",
    "#const = tf.keras.initializers.Constant(value=0.1)\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (6, 6), strides=2,\n",
    "                         activation=tf.nn.relu\n",
    "                        ),\n",
    "  tf.keras.layers.Conv2D(64, (4, 4), strides=2,\n",
    "                         activation=tf.nn.relu\n",
    "                        ),\n",
    "  tf.keras.layers.Conv2D(128, (5, 5),\n",
    "                         activation=tf.nn.relu\n",
    "                        ),\n",
    "  tf.keras.layers.Conv2D(512, (5, 5),\n",
    "                         activation=tf.nn.relu\n",
    "                        ),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512,\n",
    "                         activation=tf.nn.relu\n",
    "                       ),\n",
    "  tf.keras.layers.Dense(2,\n",
    "                         activation=None\n",
    "                       ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', f1, precision, recall, mcor, bcor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESTORE_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "197936/197936 [==============================] - 28s 142us/step - loss: 0.6794 - acc: 0.5643 - f1: 0.6661 - precision: 0.4997 - recall: 0.9990 - mcor: 2.0799e-04 - bcor: 5.0521e-05\n",
      "Epoch 2/10\n",
      "197936/197936 [==============================] - 27s 138us/step - loss: 0.6471 - acc: 0.6262 - f1: 0.6667 - precision: 0.5000 - recall: 1.0000 - mcor: 0.0014 - bcor: 1.9703e-04\n",
      "Epoch 3/10\n",
      "197936/197936 [==============================] - 28s 139us/step - loss: 0.6117 - acc: 0.6668 - f1: 0.6668 - precision: 0.5002 - recall: 0.9999 - mcor: 0.0040 - bcor: 7.0225e-04\n",
      "Epoch 4/10\n",
      "197936/197936 [==============================] - 28s 139us/step - loss: 0.5712 - acc: 0.6893 - f1: 0.6689 - precision: 0.5026 - recall: 0.9998 - mcor: 0.0457 - bcor: 0.0101\n",
      "Epoch 5/10\n",
      "197936/197936 [==============================] - 28s 139us/step - loss: 0.6602 - acc: 0.5996 - f1: 0.6667 - precision: 0.5000 - recall: 1.0000 - mcor: 0.0000e+00 - bcor: 0.0000e+00\n",
      "Epoch 6/10\n",
      "197936/197936 [==============================] - 28s 139us/step - loss: 0.5669 - acc: 0.7023 - f1: 0.6675 - precision: 0.5010 - recall: 0.9999 - mcor: 0.0210 - bcor: 0.0040\n",
      "Epoch 7/10\n",
      "197936/197936 [==============================] - 28s 139us/step - loss: 0.5101 - acc: 0.7455 - f1: 0.6699 - precision: 0.5037 - recall: 0.9998 - mcor: 0.0583 - bcor: 0.0145\n",
      "Epoch 8/10\n",
      "197936/197936 [==============================] - 28s 140us/step - loss: 0.4119 - acc: 0.8127 - f1: 0.6800 - precision: 0.5154 - recall: 0.9995 - mcor: 0.1540 - bcor: 0.0586\n",
      "Epoch 9/10\n",
      "135680/197936 [===================>..........] - ETA: 8s - loss: 0.5676 - acc: 0.6819 - f1: 0.6721 - precision: 0.5063 - recall: 0.9998 - mcor: 0.0574 - bcor: 0.0237"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "if not RESTORE_MODEL:\n",
    "    model.fit(train_data, train_labels, batch_size=128, epochs=10)\n",
    "    model.save_weights(\"./weigths.hdf5\")\n",
    "else:\n",
    "    model.load_weights(\"./weigths.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(validate_data, validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
